{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNXQe5c++ptSsXAaCoGKu+p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TochmaLia/TochmaLia/blob/main/Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oB7s8fEKisUN",
        "outputId": "193eda8d-efb6-46f1-f74c-3076c0089f47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Step: 0\tLoss: 2.282\n",
            "Train Step: 1000\tLoss: 0.337\n",
            "Train Step: 2000\tLoss: 0.210\n",
            "Train Step: 3000\tLoss: 0.079\n",
            "Train Step: 4000\tLoss: 0.139\n",
            "Train Step: 5000\tLoss: 0.168\n",
            "Train Step: 6000\tLoss: 0.133\n",
            "Train Step: 7000\tLoss: 0.053\n",
            "Train Step: 8000\tLoss: 0.032\n",
            "Train Step: 9000\tLoss: 0.065\n",
            "Train Step: 10000\tLoss: 0.043\n",
            "Train Step: 11000\tLoss: 0.019\n",
            "Train Step: 12000\tLoss: 0.042\n",
            "Train Step: 13000\tLoss: 0.008\n",
            "Train Step: 14000\tLoss: 0.036\n",
            "Train Step: 15000\tLoss: 0.031\n",
            "Train Step: 16000\tLoss: 0.016\n",
            "Train Step: 17000\tLoss: 0.013\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "is_cuda = torch.cuda.is_available()\n",
        "device = torch.device('cuda' if is_cuda else 'cpu')\n",
        "\n",
        "#\n",
        "\n",
        "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "test_data = datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "first_batch = train_loader.__iter__().__next__()\n",
        "\n",
        "#\n",
        "\n",
        "batch_size = 50\n",
        "epoch_num = 15\n",
        "learning_rate = 0.0001\n",
        "\n",
        "#\n",
        "\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "    self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "    self.dropout1 = nn.Dropout2d(0.25)\n",
        "    self.dropout2 = nn.Dropout2d(0.5)\n",
        "    self.fc1 = nn.Linear(9216, 128)\n",
        "    self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(x)\n",
        "    x=self.conv2(x)\n",
        "    x=F.relu(x)\n",
        "\n",
        "    x=F.max_pool2d(x, 2)\n",
        "\n",
        "    x=self.dropout1(x)\n",
        "    x=torch.flatten(x, 1)\n",
        "\n",
        "    x=self.fc1(x)\n",
        "    x=F.relu(x)\n",
        "\n",
        "    x=self.dropout2(x)\n",
        "    x=self.fc2(x)\n",
        "\n",
        "    output = F.log_softmax(x, dim=1)\n",
        "    return output\n",
        "\n",
        "#\n",
        "\n",
        "model = CNN().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model.train()\n",
        "i=0\n",
        "for ephoch in range(epoch_num):\n",
        "  for data, target in train_loader:\n",
        "    data = data.to(device)\n",
        "    target = target.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    loss = criterion(output, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if i % 1000 == 0:\n",
        "      print('Train Step: {}\\tLoss: {:.3f}'.format(i, loss.item()))\n",
        "    i += 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "for data, target in test_loader:\n",
        "  data = data.to(device)\n",
        "  target = target.to(device)\n",
        "  output = model(data)\n",
        "  prediction = output.data.max(1)[1]\n",
        "  correct += prediction.eq(target.data).sum()\n",
        "\n",
        "print('Test set: Accuracy : {:.2f}%'.format(100*correct/len(test_loader.dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uc2c9Gfkxohk",
        "outputId": "8408e641-ecdf-4742-ab33-0d1b5ff67766"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Accuracy : 98.95%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FKcXyMJezaji"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}